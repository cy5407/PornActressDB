# -*- coding: utf-8 -*-
"""
é©—è­‰åˆ†é›¢å¼ç·¨ç¢¼è™•ç†å¯¦æ–½
"""

from pathlib import Path
import re

def verify_implementation():
    """é©—è­‰åˆ†é›¢å¼ç·¨ç¢¼è™•ç†å¯¦æ–½"""
    
    print("ğŸ” é©—è­‰åˆ†é›¢å¼ç·¨ç¢¼è™•ç†å¯¦æ–½...")
    project_root = Path(__file__).parent / 'å¥³å„ªåˆ†é¡'
    
    checks = []
    
    # 1. æª¢æŸ¥æ—¥æ–‡ç¶²ç«™å¢å¼·å™¨æª”æ¡ˆ
    japanese_enhancer_file = project_root / 'src' / 'services' / 'japanese_site_enhancer.py'
    if japanese_enhancer_file.exists():
        with open(japanese_enhancer_file, 'r', encoding='utf-8') as f:
            content = f.read()
            if 'cp932' in content and 'av-wiki.net' in content and 'chiba-f.net' in content:
                checks.append("âœ… æ—¥æ–‡ç¶²ç«™å¢å¼·å™¨æª”æ¡ˆå­˜åœ¨ä¸”åŒ…å«æ­£ç¢ºé…ç½®")
            else:
                checks.append("âŒ æ—¥æ–‡ç¶²ç«™å¢å¼·å™¨æª”æ¡ˆå­˜åœ¨ä½†é…ç½®ä¸å®Œæ•´")
    else:
        checks.append("âŒ æ—¥æ–‡ç¶²ç«™å¢å¼·å™¨æª”æ¡ˆä¸å­˜åœ¨")
    
    # 2. æª¢æŸ¥ web_searcher.py æ˜¯å¦åŒ¯å…¥æ—¥æ–‡å¢å¼·å™¨
    web_searcher_file = project_root / 'src' / 'services' / 'web_searcher.py'
    if web_searcher_file.exists():
        with open(web_searcher_file, 'r', encoding='utf-8') as f:
            content = f.read()
            if 'from .japanese_site_enhancer import' in content:
                checks.append("âœ… web_searcher.py æ­£ç¢ºåŒ¯å…¥æ—¥æ–‡ç¶²ç«™å¢å¼·å™¨")
            else:
                checks.append("âŒ web_searcher.py æœªåŒ¯å…¥æ—¥æ–‡ç¶²ç«™å¢å¼·å™¨")
            
            if 'japanese_searcher' in content:
                checks.append("âœ… web_searcher.py åŒ…å«æ—¥æ–‡ç¶²ç«™å°ˆç”¨æœå°‹å™¨")
            else:
                checks.append("âŒ web_searcher.py æœªåŒ…å«æ—¥æ–‡ç¶²ç«™å°ˆç”¨æœå°‹å™¨")
            
            if 'create_japanese_soup' in content:
                checks.append("âœ… web_searcher.py ä½¿ç”¨æ—¥æ–‡ç·¨ç¢¼å¢å¼·å‡½å¼")
            else:
                checks.append("âŒ web_searcher.py æœªä½¿ç”¨æ—¥æ–‡ç·¨ç¢¼å¢å¼·å‡½å¼")
    else:
        checks.append("âŒ web_searcher.py æª”æ¡ˆä¸å­˜åœ¨")
    
    # 3. æª¢æŸ¥ JAVDB æœå°‹å™¨ä¿æŒåŸç‹€
    javdb_searcher_file = project_root / 'src' / 'services' / 'safe_javdb_searcher.py'
    if javdb_searcher_file.exists():
        with open(javdb_searcher_file, 'r', encoding='utf-8') as f:
            content = f.read()
            if 'encoding_enhancer' not in content and 'japanese_site_enhancer' not in content:
                checks.append("âœ… JAVDB æœå°‹å™¨ä¿æŒåŸæœ‰æ¨™æº–ç·¨ç¢¼è™•ç†")
            else:
                checks.append("âŒ JAVDB æœå°‹å™¨è¢«æ±¡æŸ“äº†ç·¨ç¢¼å¢å¼·å™¨")
    else:
        checks.append("âŒ JAVDB æœå°‹å™¨æª”æ¡ˆä¸å­˜åœ¨")
    
    # 4. æª¢æŸ¥èˆŠçš„ç·¨ç¢¼å¢å¼·å™¨æ˜¯å¦å·²ç§»é™¤
    old_enhancer_file = project_root / 'src' / 'services' / 'encoding_enhancer.py'
    if not old_enhancer_file.exists():
        checks.append("âœ… èˆŠçš„ç·¨ç¢¼å¢å¼·å™¨å·²ç§»é™¤ï¼Œé¿å…è¡çª")
    else:
        checks.append("âš ï¸ èˆŠçš„ç·¨ç¢¼å¢å¼·å™¨ä»å­˜åœ¨ï¼Œå¯èƒ½é€ æˆè¡çª")
    
    # 5. è¼¸å‡ºçµæœ
    print("\nğŸ“‹ æª¢æŸ¥çµæœ:")
    for check in checks:
        print(f"   {check}")
    
    success_count = len([c for c in checks if c.startswith("âœ…")])
    total_count = len([c for c in checks if not c.startswith("âš ï¸")])
    
    print(f"\nğŸ“Š ç¸½çµ: {success_count}/{total_count} é …æª¢æŸ¥é€šé")
    
    if success_count == total_count:
        print("ğŸ‰ åˆ†é›¢å¼ç·¨ç¢¼è™•ç†å¯¦æ–½å®Œæˆï¼")
        print("\nğŸ¯ é æœŸæ•ˆæœ:")
        print("   - æ—¥æ–‡ç¶²ç«™ (av-wiki.net, chiba-f.net) ä½¿ç”¨ CP932 ç·¨ç¢¼")
        print("   - JAVDB ä¿æŒ UTF-8 æ¨™æº–ç·¨ç¢¼")
        print("   - æ—¥æ–‡ç¶²ç«™ä½¿ç”¨è¼ƒçŸ­å»¶é² (0.5-1.5ç§’)")
        print("   - ç·¨ç¢¼è­¦å‘Šå•é¡Œæ‡‰å·²è§£æ±º")
        return True
    else:
        print("âŒ å¯¦æ–½ä¸å®Œæ•´ï¼Œè«‹æª¢æŸ¥å¤±æ•—é …ç›®")
        return False

if __name__ == "__main__":
    verify_implementation()