# 女優分類系統功能詳細說明書
**版本**: v2.0-stable  
**日期**: 2025-06-22  
**分支**: feature/web-scraper-refactor  

## 專案概覽

本專案是一個基於 Python 開發的智慧影片分類系統，專門用於自動整理和分類 AV 影片檔案。系統能夠透過網路爬蟲取得女優和片商資訊，並根據智慧分類邏輯自動整理檔案結構。

## 系統架構

### 核心模組結構
```
女優分類/
├── src/                    # 核心原始碼
│   ├── models/            # 資料模型
│   │   ├── database.py    # 資料庫操作類別
│   │   └── actress.py     # 女優模型
│   ├── services/          # 業務邏輯服務
│   │   ├── studio_classifier.py  # 片商分類器
│   │   ├── web_scraper.py        # 網路爬蟲
│   │   └── file_manager.py       # 檔案管理器
│   ├── ui/               # 使用者介面
│   │   ├── main_window.py # 主視窗
│   │   └── dialog.py      # 對話框組件
│   └── utils/            # 工具函式
├── data/                 # 資料檔案
├── cache/               # 快取資料
├── config/              # 設定檔案
└── tests/               # 測試腳本
```

## 核心功能模組

### 1. 資料庫管理模組 (database.py)
**功能**:
- SQLite 資料庫初始化與維護
- 女優、片商、影片資訊的 CRUD 操作
- 資料庫結構自動檢查與修復

**關鍵方法**:
- `create_tables()`: 建立資料庫表格
- `add_actress()`: 新增女優資訊
- `get_actress_info()`: 查詢女優資料
- `update_studio_info()`: 更新片商資訊

**狀態**: ✅ 穩定運作，已通過測試

### 2. 片商分類器 (studio_classifier.py)
**功能**:
- 實作「大片商優先」分類邏輯
- 根據女優作品歷史判斷分類方式
- 支援多層級片商分類

**核心邏輯**:
```python
if has_major_studio_works(actress):
    return classify_by_major_studio()
else:
    return classify_by_solo_or_planning()
```

**狀態**: ✅ 已優化，通過全面測試

### 3. 網路爬蟲模組 (web_scraper.py)
**功能**:
- 從 AV-WIKI、JAVDB、CHIBA-F 等網站爬取資料
- 多編碼支援 (UTF-8, Shift-JIS, CP932)
- 自動重試與錯誤處理

**已知問題**:
- 🔄 編碼問題偶發
- 🔄 併發處理效能待優化
- 🔄 缺乏快取機制

**優化進行中**: 參考「網路爬蟲模組優化建議書_2025-06-22.md」

### 4. 檔案管理模組 (file_manager.py)
**功能**:
- 智慧檔案移動與重新命名
- 資料夾結構自動建立
- 重複檔案檢測與處理

**狀態**: ✅ 核心功能完成

### 5. 圖形化介面模組 (UI)
**功能**:
- 主視窗操作介面
- 批次處理進度顯示
- 互動式分類選擇對話框
- 系統設定管理

**狀態**: ✅ 基本功能完成

## 智慧分類邏輯

### 大片商優先原則
系統採用「大片商優先」的分類邏輯，確保具有主流片商作品歷史的女優不會被錯誤歸類為企劃女優。

### 分類流程
1. **檢查大片商歷史**: 查詢女優是否有大片商作品
2. **應用分類規則**: 
   - 有大片商歷史 → 大片商分類
   - 無大片商歷史 → 單體/企劃分類
3. **檔案移動**: 根據分類結果移動檔案

### 支援的大片商列表
- S1 NO.1 STYLE
- MOODYZ
- PREMIUM
- ideapocket
- kawaii
- MUTEKI
- kira☆kira
- E-BODY
- Fitch
- Madonna
- 溫泉湯けむり旅行
- Attackers

## 資料來源與爬蟲

### 支援的資料網站
1. **AV-WIKI** (主要資料源)
   - 女優基本資訊
   - 作品列表與片商資訊
   
2. **JAVDB** (補充資料源)
   - 詳細作品資訊
   - 高品質封面圖片
   
3. **CHIBA-F** (備用資料源)
   - 額外女優資料
   - 作品評分資訊

### 爬蟲特色
- 多重編碼處理
- 自動重試機制
- 頻率控制避免封鎖
- 快取機制減少重複請求

## 資料庫架構

### actresses 表格
```sql
CREATE TABLE actresses (
    id INTEGER PRIMARY KEY,
    name TEXT UNIQUE,
    classification TEXT,
    studio_type TEXT,
    last_updated TIMESTAMP
);
```

### studios 表格
```sql
CREATE TABLE studios (
    id INTEGER PRIMARY KEY,
    name TEXT UNIQUE,
    is_major BOOLEAN,
    category TEXT
);
```

### videos 表格
```sql
CREATE TABLE videos (
    id INTEGER PRIMARY KEY,
    filename TEXT UNIQUE,
    actress_name TEXT,
    studio_name TEXT,
    processed BOOLEAN,
    created_at TIMESTAMP
);
```

## 設定與配置

### 主要設定檔 (config.ini)
```ini
[DATABASE]
db_path = data/actresses.db
backup_enabled = true

[SCRAPER]
delay_min = 1
delay_max = 3
retry_attempts = 3
timeout = 30

[CLASSIFICATION]
enable_major_studio_priority = true
unknown_handling = interactive

[UI]
theme = modern
language = zh-tw
```

## 測試與驗證

### 自動化測試腳本
- `test_new_classification_logic.py`: 分類邏輯測試
- `verify_new_logic.py`: 邏輯驗證測試
- `comprehensive_test_report.py`: 綜合測試報告
- `check_database_structure.py`: 資料庫結構檢查

### 測試覆蓋率
- 分類邏輯: ✅ 100%
- 資料庫操作: ✅ 95%
- 網路爬蟲: 🔄 85% (優化中)
- UI 互動: ✅ 90%

## 已知問題與限制

### 目前問題
1. **網路爬蟲模組**:
   - 編碼處理需要加強
   - 併發處理效能可以改善
   - 缺乏完整的快取機制

2. **效能優化**:
   - 大量檔案處理時記憶體使用較高
   - 資料庫查詢可以進一步優化

3. **錯誤處理**:
   - 網路連線中斷的復原機制
   - 檔案權限問題的處理

### 限制
- 目前僅支援 Windows 平台
- 需要穩定的網路連線
- 處理大量檔案時需要足夠的磁碟空間

## 未來開發計劃

### 即將進行的優化 (當前分支)
1. **網路爬蟲重構**:
   - 多編碼自動檢測
   - 非同步爬蟲實作
   - 智慧快取系統
   - 頻率控制機制

2. **效能提升**:
   - 資料庫查詢優化
   - 記憶體使用優化
   - 併發處理改善

### 長期目標
1. **平台支援**: 擴展至 Linux 和 macOS
2. **雲端整合**: 支援雲端資料庫同步
3. **AI 增強**: 整合機器學習進行智慧分類
4. **API 開發**: 提供 REST API 介面

## 使用指南

### 快速啟動
```bash
cd 女優分類
python run.py
```

### 批次處理模式
```bash
python run.py --batch --input-dir "C:\Videos" --output-dir "C:\Organized"
```

### 設定模式
```bash
python run.py --config
```

## 維護與支援

### 定期維護
- 資料庫備份 (每日自動)
- 快取清理 (每週自動)
- 日誌檔案輪替

### 故障排除
常見問題解決方案請參考 `docs/troubleshooting.md`

### 版本更新
```bash
git pull origin main
pip install -r requirements.txt
python setup.py migrate
```

## 技術規格

### 系統需求
- **作業系統**: Windows 10+ (64-bit)
- **Python**: 3.8 或更高版本
- **記憶體**: 建議 4GB 以上
- **磁碟空間**: 建議 1GB 可用空間
- **網路**: 穩定的網際網路連線

### 相依套件
```
requests>=2.28.0
sqlite3 (內建)
tkinter (內建)
beautifulsoup4>=4.11.0
lxml>=4.9.0
chardet>=5.0.0
```

## 結語

本系統已經過充分測試，核心功能穩定可靠。目前正在進行網路爬蟲模組的重構優化，預計將大幅提升系統效能和穩定性。

如有任何問題或建議，請透過 Git 倉庫的 Issue 功能回報。

---
**最後更新**: 2025-06-22  
**分支**: feature/web-scraper-refactor  
**狀態**: 開發中 - 網路爬蟲模組優化階段
