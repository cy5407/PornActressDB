# 🎯 日文網站搜尋功能修正指南

## 📋 問題診斷結果

### 🔍 根本原因
1. **Brotli 壓縮問題**：日文網站使用 `content-encoding: br`（Brotli 壓縮）
2. **httpx 自動解壓失敗**：httpx 在處理 Brotli 壓縮時出現問題
3. **編碼檢測失效**：由於解壓問題，所有編碼檢測都失敗

### ✅ 解決方案
**關鍵發現**：禁用 `Accept-Encoding` 標頭後，網站會回傳未壓縮的 HTML，且能找到 `actress-name` 元素！

## 🛠️ 需要修正的檔案

### 1. `web_searcher.py`
**問題**：使用了會觸發 Brotli 壓縮的標頭
**修正**：移除或修改 `Accept-Encoding` 標頭

### 2. `japanese_site_enhancer.py` 
**問題**：編碼檢測邏輯複雜但無效
**修正**：簡化邏輯，專注於未壓縮內容的處理

### 3. `classifier_core.py`
**狀態**：分離搜尋方法需要新增
**修正**：新增 `process_and_search_japanese_sites` 和 `process_and_search_javdb` 方法

## 🎯 具體修正步驟

### 步驟 1：修正 `web_searcher.py` 的 HTTP 標頭
```python
# 為日文網站使用特殊的標頭配置
japanese_headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'ja,en-US;q=0.7,en;q=0.3',
    # 關鍵：不包含 Accept-Encoding 以避免 Brotli 壓縮
    'Connection': 'keep-alive',
}
```

### 步驟 2：更新日文網站搜尋方法
```python
def make_japanese_request(url, **kwargs):
    with httpx.Client(timeout=self.timeout, **kwargs) as client:
        # 使用不支援壓縮的標頭
        response = client.get(url, headers=self.japanese_headers)
        response.raise_for_status()
        return BeautifulSoup(response.text, 'html.parser')
```

### 步驟 3：新增 `classifier_core.py` 分離搜尋方法

### 步驟 4：測試和驗證

## 📝 完整修正程式碼

### A. 修正 `web_searcher.py`

需要在 `__init__` 方法中新增日文網站專用標頭：
```python
# 日文網站專用標頭（避免 Brotli 壓縮問題）
self.japanese_headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'ja,en-US;q=0.7,en;q=0.3',
    # 關鍵：不包含 Accept-Encoding 以避免壓縮
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1'
}
```

修正 `_search_av_wiki` 和 `_search_chiba_f_net` 方法：
```python
def make_request(url, **kwargs):
    with httpx.Client(timeout=self.timeout, **kwargs) as client:
        # 使用日文網站專用標頭
        response = client.get(url, headers=self.japanese_headers)
        response.raise_for_status()
        return BeautifulSoup(response.text, 'html.parser')
```

### B. 新增 `classifier_core.py` 分離搜尋方法

```python
def process_and_search_japanese_sites(self, folder_path: str, stop_event: threading.Event, progress_callback=None):
    \"\"\"僅使用日文網站搜尋 (AV-WIKI 和 chiba-f.net)\"\"\"
    # 使用 self.web_searcher.search_japanese_sites 作為搜尋方法
    
def process_and_search_javdb(self, folder_path: str, stop_event: threading.Event, progress_callback=None):
    \"\"\"僅使用 JAVDB 搜尋\"\"\"
    # 使用 self.web_searcher.search_javdb_only 作為搜尋方法
```

### C. 確保 GUI 按鈕正確綁定

GUI 中的按鈕已經正確設定：
- 🇯🇵 日文網站搜尋 → `start_japanese_search()`
- 📊 JAVDB 搜尋 → `start_javdb_search()`

## 🧪 測試計劃

1. **單元測試**：測試單個番號的日文網站搜尋
2. **整合測試**：測試完整的分離搜尋流程
3. **GUI 測試**：驗證兩個按鈕功能正常
4. **編碼測試**：確認女優名稱正確顯示

## 🎉 預期結果

修正後應該能夠：
1. ✅ 日文網站搜尋找到女優資訊
2. ✅ 女優名稱正確顯示（無亂碼）
3. ✅ GUI 分離按鈕功能正常
4. ✅ 資料正確寫入資料庫

---

**下一步**：請將此指南提供給 Claude Code 執行完整修正。
